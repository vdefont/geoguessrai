{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "novel-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import NamedTuple\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "north-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "def pkl_save(path, obj):\n",
    "  with open(path, 'wb') as file:\n",
    "    pickle.dump(obj, file)\n",
    "\n",
    "def pkl_load(path):\n",
    "  with open(path, 'rb') as file:\n",
    "    return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "revolutionary-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheekyLoadingBar(threading.Thread):\n",
    "    def __init__(self, out, text, eta):\n",
    "        super().__init__()\n",
    "        label = widgets.Label(text)\n",
    "        self.bar = widgets.FloatProgress(value=0,min=0,max=1)\n",
    "        to_display = widgets.HBox([label, self.bar])\n",
    "        \n",
    "        self.delay = 0.01\n",
    "        self.incr_start = self.delay / eta\n",
    "        self.incr = self.incr_start\n",
    "        self.alpha = 1 - self.incr\n",
    "        \n",
    "        self.done = False\n",
    "        \n",
    "        with out:\n",
    "            display(to_display)\n",
    "    \n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "        self.wait_target = self.start_time\n",
    "        super().start()\n",
    "    \n",
    "    def run(self):\n",
    "        while self.bar.value < 1:\n",
    "            self.wait_target += self.delay\n",
    "            diff = self.wait_target - time.time()\n",
    "            if diff > 0:\n",
    "                time.sleep(diff)\n",
    "            self.bar.value += self.incr\n",
    "            # Cheekily slow down progress\n",
    "            self.incr *= self.alpha\n",
    "        self.done = True\n",
    "    \n",
    "    def stop(self):\n",
    "        self.incr = self.incr_start\n",
    "        while not self.done:\n",
    "            self.incr *= 1.02\n",
    "            time.sleep(self.delay)\n",
    "        self.join()\n",
    "        self.bar.bar_style='success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "underlying-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEAREST NEIGHBORS LOGIC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "understanding-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Params:\n",
    "- k (num neighbors)\n",
    "    - cur: 5\n",
    "- m (preference for closest onces)\n",
    "    - cur: 10\n",
    "- sigma (units: lat/lng)\n",
    "    - cur: 4\n",
    "Minor:\n",
    "- scale\n",
    "    - determines the granularity of our map\n",
    "    - scale=100 creates units of 1/100 lat (resp. lng)\n",
    "- truncate\n",
    "    - how many stdevs out to truncate filters\n",
    "    - smaller is more efficient\n",
    "    - in general, see how small I can make it without hurting results\n",
    "\"\"\"\n",
    "\n",
    "class Config(NamedTuple):\n",
    "    K: int\n",
    "    M: int\n",
    "    SIGMA: int\n",
    "    SCALE: int\n",
    "    TRUNCATE: int\n",
    "        \n",
    "CONFIG = Config(\n",
    "    K = 20,\n",
    "    M = 5,\n",
    "    SIGMA = 4,\n",
    "    SCALE = 10,\n",
    "    TRUNCATE = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prospective-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "logits_country = pkl_load(\"logits/logits_country\")\n",
    "logits_geocell_1 = pkl_load(\"logits/logits_geocell_1\")\n",
    "logits_geocell_2 = pkl_load(\"logits/logits_geocell_2\")\n",
    "logits_us = pkl_load('logits/logits_us')\n",
    "\n",
    "X_us = np.concatenate([logits_country, logits_geocell_1, logits_geocell_2, logits_us], 1)\n",
    "X_no_us = np.concatenate([logits_country, logits_geocell_1, logits_geocell_2], 1)\n",
    "y = np.array(data[[\"lat\", \"lng\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electric-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_filter():\n",
    "    half_width = int(CONFIG.TRUNCATE*CONFIG.SIGMA*CONFIG.SCALE)\n",
    "    zs = np.zeros([2*half_width+1]*2)\n",
    "    zs[half_width,half_width]=1\n",
    "    return gaussian_filter(zs, sigma=CONFIG.SIGMA*CONFIG.SCALE, truncate=CONFIG.TRUNCATE)\n",
    "\n",
    "MAIN = csr_matrix((180*CONFIG.SCALE, 360*CONFIG.SCALE))\n",
    "BASE_FILTER = get_base_filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prescribed-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(lat_lng, weight):        \n",
    "    lat, lng = lat_lng\n",
    "    # Rescale starting at zero\n",
    "    lat += 90.0\n",
    "    lng += 180.0\n",
    "    # Get x and y indices\n",
    "    lat_idx = round(lat*CONFIG.SCALE)\n",
    "    lng_idx = round(lng*CONFIG.SCALE)\n",
    "    # Make filter\n",
    "    data = BASE_FILTER.copy() * weight\n",
    "    \n",
    "    # Put filter into sparse array of the same shape as \"main\"\n",
    "    \n",
    "    # b = \"big\", s = \"small\", c = \"center\"\n",
    "    hb, wb = MAIN.shape\n",
    "    hs, ws = data.shape\n",
    "    hc, wc = lat_idx, lng_idx\n",
    "    \n",
    "    # Get row and col indices\n",
    "    row, col = np.meshgrid(range(hs), range(ws))\n",
    "    row = row.T.flatten()\n",
    "    col = col.T.flatten()\n",
    "\n",
    "    # Re-center them\n",
    "    row = row - hs // 2 + hc\n",
    "    col = col - ws // 2 + wc\n",
    "    \n",
    "    # Remove out-of-bounds indices\n",
    "    df = pd.DataFrame({'row': row, 'col': col, 'data': data.flatten()})\n",
    "    df = df[(df.row >= 0) & (df.col >= 0) & (df.row < hb) & (df.col < wb)]\n",
    "    \n",
    "    # Return sparse matrix\n",
    "    row, col, data = df.row.tolist(), df.col.tolist(), df.data.tolist()\n",
    "    return csr_matrix((data, (row, col)), shape=MAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fitted-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_lat_lng(filts):\n",
    "    lat_idx_max = filts.max(1).argmax()\n",
    "    lng_idx_max = filts.max(0).argmax()\n",
    "    lat_max = (lat_idx_max/CONFIG.SCALE) - 90\n",
    "    lng_max = (lng_idx_max/CONFIG.SCALE) - 180\n",
    "    return lat_max, lng_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wanted-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(indices, weights, top=None):\n",
    "    neighbor_locs = y[indices][0] # (K, 2)\n",
    "    neighbor_weights = weights[0]\n",
    "\n",
    "    main = deepcopy(MAIN)\n",
    "    rows = []\n",
    "    for lat_lng, weight in zip(neighbor_locs, neighbor_weights):\n",
    "        main += make_filter(lat_lng=lat_lng, weight=weight)\n",
    "    return get_best_lat_lng(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cleared-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neighbors(nn, logits, cheeky_lb=None):\n",
    "    X_test = logits.reshape(1, -1)\n",
    "    distances, indices = nn.kneighbors(X_test)\n",
    "    weights = (1/distances)**CONFIG.M\n",
    "    weights /= weights.sum(1, keepdims=True)\n",
    "    if cheeky_lb: cheeky_lb.start()\n",
    "    pred = predict(indices, weights)\n",
    "    if cheeky_lb: cheeky_lb.stop()\n",
    "    pred_df = pd.DataFrame([list(pred)]).rename(columns={0:'lat',1:'lng'})\n",
    "    \n",
    "    z1 = y[indices][0]\n",
    "    z2 = weights[0].reshape(-1,1)\n",
    "    data = pd.DataFrame(np.concatenate([z1, z2], 1))\n",
    "    data = data.rename(columns={0: 'lat', 1: 'lng', 2: 'similarity'})\n",
    "    data['size'] = 1\n",
    "\n",
    "    fig = px.scatter_mapbox(\n",
    "        data,\n",
    "        lat='lat',\n",
    "        lon='lng',\n",
    "        color='similarity',\n",
    "        size='size',\n",
    "        size_max=10,\n",
    "        color_continuous_scale=px.colors.sequential.Plasma_r,\n",
    "    )\n",
    "    \n",
    "    # Add green circle for prediction\n",
    "    pred_df['color'] = 'rgb(50,220,50)'\n",
    "    pred_df['size'] = 1\n",
    "    trace = px.scatter_mapbox(\n",
    "        pred_df, \n",
    "        lat='lat', \n",
    "        lon='lng',\n",
    "        size='size',\n",
    "        size_max=10,\n",
    "        color='color',\n",
    "        color_discrete_map='identity',\n",
    "    ).data[0]\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "    fig.update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        mapbox=dict(\n",
    "            center={'lat': pred_df.lat[0], 'lon': pred_df.lng[0]},\n",
    "            zoom=2,\n",
    "        ),\n",
    "        margin=dict(t=0, b=0, l=0, r=0),\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "binding-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN LOGIC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "under-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_COUNTRY = ['United Arab Emirates','Albania', 'Argentina','American Samoa','Austria', 'Australia','Bangladesh','Belgium', 'Bulgaria','Bolivia, Plurinational State of','Brazil', 'Bhutan','Botswana', 'Canada','Switzerland','Chile', 'China','Colombia','Czech Republic','Germany','Denmark','Dominican Republic','Ecuador','Estonia','Egypt','Spain','Finland','Faroe Islands','France','United Kingdom','Ghana','Greenland','Greece', 'Guatemala', 'Hong Kong','Croatia','Hungary','Indonesia', 'Ireland','Israel','India','Iceland','Italy','Jordan','Japan','Kenya','Kyrgyzstan','Cambodia','Korea, Republic of','Sri Lanka', 'Lesotho','Lithuania','Latvia','Madagascar','Macedonia, the Former Yugoslav Republic of','Mongolia','Mexico','Malaysia','Nigeria','Netherlands','Norway','New Zealand','Peru','Philippines','Pakistan','Poland','Puerto Rico','Portugal','Romania','Serbia','Russian Federation','Sweden','Singapore','Slovenia','Slovakia','Senegal','Swaziland','Thailand','Tunisia','Turkey','Taiwan, Province of China','Ukraine','Uganda','United States','Uruguay','Viet Nam', 'South Africa']\n",
    "VOCAB_US = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "breathing-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_url(url):\n",
    "    n = r'([\\d\\.-]*)'\n",
    "    res = re.search(fr'@{n},{n},.*,{n}h,{n}t', url)\n",
    "    \n",
    "    # Not a google maps URL\n",
    "    if res is None:\n",
    "        return url\n",
    "    \n",
    "    lat, lng, heading, pitch = [float(res.group(i)) for i in range(1,5)]\n",
    "    # URL pitch ranges 0 to 180, scrape API ranges -90 to 90\n",
    "    pitch -= 90\n",
    "\n",
    "    scrub3key = 'AIzaSyABWCcImw44lzIqLHzBIJLngYLTx5El11M'\n",
    "    params = {\n",
    "        'size': '480x480',\n",
    "        'location': f'{lat},{lng}',\n",
    "        'heading': str(heading),\n",
    "        'pitch': str(pitch),\n",
    "        'fov': '105',\n",
    "        'key': scrub3key,\n",
    "    }\n",
    "    url = \"https://maps.googleapis.com/maps/api/streetview\"\n",
    "    url_params = \"&\".join(f\"{k}={v}\" for k, v in params.items())\n",
    "    return f\"{url}?{url_params}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "substantial-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(arr):\n",
    "    exp = np.exp(arr)\n",
    "    return exp / exp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "elect-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logits(NamedTuple):\n",
    "    COUNTRY: np.array\n",
    "    GEOCELL: np.array\n",
    "    US: np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "respected-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_out(url):\n",
    "    # Returns logits_country: List[float]\n",
    "    params = {\n",
    "        'code': 'iZP6dHFLCjWvmLQx9v1haxW8Du21Phk/hMTQj4c/aGJseXAMgWuOPw==',\n",
    "        'img': url,\n",
    "    }\n",
    "    model_url = 'https://countryfinal.azurewebsites.net/api/classify'\n",
    "    res = requests.get(url=model_url, params=params).json()\n",
    "    \n",
    "    return Logits(\n",
    "        COUNTRY = np.array(res['logits_country']),\n",
    "        GEOCELL = np.array(res['logits_geocell']),\n",
    "        US = np.array(res['logits_us']),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "productive-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_preds(model_out):\n",
    "    logits = model_out.COUNTRY\n",
    "    probs = softmax(logits)\n",
    "\n",
    "    df = pd.DataFrame({'Country': VOCAB_COUNTRY, 'Confidence': probs})\n",
    "    df = df.sort_values('Confidence', ascending=False)\n",
    "    df.Confidence = (df.Confidence * 100).round(2)\n",
    "    df = df[df.Confidence > 0.].iloc[:10]\n",
    "    df.Confidence = df.Confidence.astype(str) + '%'\n",
    "    df = df.set_index('Country')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "tamil-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_preds(model_out):\n",
    "    logits = model_out.US\n",
    "    probs = softmax(logits)\n",
    "\n",
    "    df = pd.DataFrame({'US State': VOCAB_US, 'Confidence': probs})\n",
    "    df = df.sort_values('Confidence', ascending=False)\n",
    "    df.Confidence = (df.Confidence * 100).round(2)\n",
    "    df = df[df.Confidence > 0.].iloc[:10]\n",
    "    df.Confidence = df.Confidence.astype(str) + '%'\n",
    "    df = df.set_index('US State')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "biological-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_and_get_nns():\n",
    "    WARMUP_URL = \"https://maps.googleapis.com/maps/api/streetview?size=480x480&location=42.3014176,-71.3006286&heading=233.55&pitch=5.1&fov=105&key=AIzaSyABWCcImw44lzIqLHzBIJLngYLTx5El11M\"\n",
    "    _out = get_model_out(WARMUP_URL)\n",
    "    NN_us = NearestNeighbors(n_neighbors=CONFIG.K).fit(X_us)\n",
    "    NN_no_us = NearestNeighbors(n_neighbors=CONFIG.K).fit(X_no_us)\n",
    "    return NN_us, NN_no_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "daily-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_and_get_nns_DUMMY():\n",
    "    time.sleep(5)\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "designing-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmaps_link_text():\n",
    "    return (\n",
    "        \"<a href=http://google.com/maps target='_blank' style='color:blue;'=>Google Maps</a>\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aware-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2a = widgets.Label(\"1. Open \")\n",
    "e2b = widgets.HTML(value=gmaps_link_text())\n",
    "e2c = widgets.Label(\" and go to any Street View location in the world\")\n",
    "e3 = widgets.Label(\" (do this by dragging the little yellow person in the bottom right corner of Google Maps onto any road)\")\n",
    "e4 = widgets.Label(\"2. Copy the URL and paste it below\")\n",
    "e5 = widgets.Label('3. Click \"Predict\"! (this button will appear once my models finish downloading)')\n",
    "\n",
    "layout = widgets.Layout(\n",
    "    display='flex',\n",
    "    flex_flow='column',\n",
    "    padding='0px',\n",
    "    border='0px'\n",
    ")\n",
    "expl = widgets.VBox([\n",
    "    widgets.HBox([e2a,e2b,e2c]), e3, e4, e5\n",
    "], layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "minor-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_url = widgets.Text(placeholder='Paste the url here...')\n",
    "btn_clear = widgets.Button(description=\"Clear\")\n",
    "waiting = widgets.Output()\n",
    "\n",
    "s1 = widgets.Label(\"While you're waiting, go to \")\n",
    "s2 = widgets.HTML(value=gmaps_link_text())\n",
    "s3 = widgets.Label(\"and pick a Street View image!\")\n",
    "suggestion = widgets.HBox([s1, s2, s3])\n",
    "\n",
    "btn_run = widgets.Button(description=\"Predict Location\")\n",
    "err = widgets.Output()\n",
    "model_sees_out = widgets.Output()\n",
    "model_sees = widgets.Label(\"What the model sees:\")\n",
    "img_out = widgets.Output()\n",
    "pred_out_country = widgets.Output()\n",
    "pred_out_us = widgets.Output()\n",
    "waiting_pred_loc = widgets.Output()\n",
    "loc_expl_output = widgets.Output()\n",
    "loc_expl = widgets.VBox([\n",
    "    widgets.Label(\"Here are the most similar places in my database.\"),\n",
    "    widgets.Label(\"The green dot my final guess (a weighted average of similar places)\"),\n",
    "])\n",
    "pred_loc = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "boxed-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text_url(_):\n",
    "    text_url.value = ''\n",
    "\n",
    "btn_clear.on_click(clear_text_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "rubber-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnClickClassify:\n",
    "    def __init__(self):\n",
    "        self.NN_us = None\n",
    "        self.NN_no_us = None\n",
    "        \n",
    "    def click(self, change):\n",
    "        if len(text_url.value) == 0:\n",
    "            with err:\n",
    "                print(\"Please paste an image URL first!\")\n",
    "            return\n",
    "\n",
    "        for elt in [model_sees_out, img_out, pred_out_country, \n",
    "                    pred_out_us, waiting_pred_loc, loc_expl_output, \n",
    "                    pred_loc]:\n",
    "            elt.clear_output()\n",
    "\n",
    "        url = convert_url(text_url.value)\n",
    "        with urlopen(url) as testImage:\n",
    "            image = Image.open(testImage)\n",
    "            image.thumbnail((256,256), Image.ANTIALIAS)\n",
    "\n",
    "        with model_sees_out:\n",
    "            display(model_sees)\n",
    "        with img_out:\n",
    "            display(image)\n",
    "\n",
    "        model_out = get_model_out(url)\n",
    "        waiting.clear_output()\n",
    "\n",
    "        with pred_out_country:\n",
    "            display(country_preds(model_out))\n",
    "\n",
    "        with pred_out_us:\n",
    "            display(us_preds(model_out))\n",
    "\n",
    "        is_us = VOCAB_COUNTRY[model_out.COUNTRY.argmax()] == \"United States\"\n",
    "        if is_us:\n",
    "            nn = self.NN_us\n",
    "            logits_cat = np.concatenate([model_out.COUNTRY, model_out.GEOCELL, model_out.US])\n",
    "        else:\n",
    "            nn = self.NN_no_us\n",
    "            logits_cat = np.concatenate([model_out.COUNTRY, model_out.GEOCELL])\n",
    "        pred_loc_lb = CheekyLoadingBar(waiting_pred_loc, \"Predicting Precise Location\", 10)\n",
    "        pred_loc_lb.start()\n",
    "        with pred_loc:\n",
    "            plot_neighbors(nn, logits_cat)\n",
    "        with loc_expl_output:\n",
    "            display(loc_expl)\n",
    "        pred_loc_lb.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "alert-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = OnClickClassify()\n",
    "btn_run.on_click(occ.click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "sublime-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = widgets.VBox([\n",
    "    expl,\n",
    "    widgets.HBox([text_url, btn_clear]),\n",
    "    waiting,\n",
    "    suggestion,\n",
    "    btn_run,\n",
    "    err,\n",
    "    model_sees_out,\n",
    "    img_out,\n",
    "    widgets.HBox([pred_out_country, pred_out_us]),\n",
    "    waiting_pred_loc,\n",
    "    loc_expl_output,\n",
    "    pred_loc,\n",
    "])\n",
    "main.layout.visibility = 'hidden'\n",
    "btn_start_main = widgets.Button(description=\"Start!\")\n",
    "\n",
    "def start_main(_):\n",
    "    btn_start_main.layout.display = 'none'\n",
    "    main.layout.visibility = None\n",
    "    \n",
    "    btn_run.layout.visibility = 'hidden'\n",
    "    btn_clear.layout.visibility = 'hidden'\n",
    "\n",
    "    pb = CheekyLoadingBar(waiting, \"Downloading model\", 25)\n",
    "    pb.start()\n",
    "    NN_us, NN_no_us = warmup_and_get_nns()\n",
    "    occ.NN_us = NN_us\n",
    "    occ.NN_no_us = NN_no_us\n",
    "    pb.stop()\n",
    "\n",
    "    suggestion.layout.display = 'none' # Remove\n",
    "    btn_run.layout.visibility = None # Put back\n",
    "    btn_clear.layout.visibility = None # Put back\n",
    "    \n",
    "btn_start_main.on_click(start_main)\n",
    "\n",
    "main_wrapper = widgets.VBox([btn_start_main, main])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fossil-capacity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e627da93af54003a79891a149bd0d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Start!', style=ButtonStyle()), VBox(children=(VBox(children=(HBox(children=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(main_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-queen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
