{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "novel-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import NamedTuple\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "north-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "def pkl_save(path, obj):\n",
    "  with open(path, 'wb') as file:\n",
    "    pickle.dump(obj, file)\n",
    "\n",
    "def pkl_load(path):\n",
    "  with open(path, 'rb') as file:\n",
    "    return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "underlying-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEAREST NEIGHBORS LOGIC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "understanding-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Params:\n",
    "- k (num neighbors)\n",
    "    - cur: 5\n",
    "- m (preference for closest onces)\n",
    "    - cur: 10\n",
    "- sigma (units: lat/lng)\n",
    "    - cur: 4\n",
    "Minor:\n",
    "- scale\n",
    "    - determines the granularity of our map\n",
    "    - scale=100 creates units of 1/100 lat (resp. lng)\n",
    "- truncate\n",
    "    - how many stdevs out to truncate filters\n",
    "    - smaller is more efficient\n",
    "    - in general, see how small I can make it without hurting results\n",
    "\"\"\"\n",
    "\n",
    "class Config(NamedTuple):\n",
    "    K: int\n",
    "    M: int\n",
    "    SIGMA: int\n",
    "    SCALE: int\n",
    "    TRUNCATE: int\n",
    "        \n",
    "CONFIG = Config(\n",
    "    K = 20,\n",
    "    M = 5,\n",
    "    SIGMA = 4,\n",
    "    SCALE = 10,\n",
    "    TRUNCATE = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prospective-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "logits_country = pkl_load(\"logits/country\")\n",
    "logits_geocell_1 = pkl_load(\"logits/geocell_1\")\n",
    "logits_geocell_2 = pkl_load(\"logits/geocell_2\")\n",
    "logits_us = pkl_load('logits/us')\n",
    "\n",
    "X = np.concatenate([logits_country, logits_geocell_1, logits_geocell_2, logits_us], 1)\n",
    "y = np.array(data[[\"lat\", \"lng\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "legal-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NearestNeighbors(n_neighbors=CONFIG.K).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "electric-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_filter():\n",
    "    half_width = int(CONFIG.TRUNCATE*CONFIG.SIGMA*CONFIG.SCALE)\n",
    "    zs = np.zeros([2*half_width+1]*2)\n",
    "    zs[half_width,half_width]=1\n",
    "    return gaussian_filter(zs, sigma=CONFIG.SIGMA*CONFIG.SCALE, truncate=CONFIG.TRUNCATE)\n",
    "\n",
    "MAIN = csr_matrix((180*CONFIG.SCALE, 360*CONFIG.SCALE))\n",
    "BASE_FILTER = get_base_filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "prescribed-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter(lat_lng, weight):        \n",
    "    lat, lng = lat_lng\n",
    "    # Rescale starting at zero\n",
    "    lat += 90.0\n",
    "    lng += 180.0\n",
    "    # Get x and y indices\n",
    "    lat_idx = round(lat*CONFIG.SCALE)\n",
    "    lng_idx = round(lng*CONFIG.SCALE)\n",
    "    # Make filter\n",
    "    data = BASE_FILTER.copy() * weight\n",
    "    \n",
    "    # Put filter into sparse array of the same shape as \"main\"\n",
    "    \n",
    "    # b = \"big\", s = \"small\", c = \"center\"\n",
    "    hb, wb = MAIN.shape\n",
    "    hs, ws = data.shape\n",
    "    hc, wc = lat_idx, lng_idx\n",
    "    \n",
    "    # Get row and col indices\n",
    "    row, col = np.meshgrid(range(hs), range(ws))\n",
    "    row = row.T.flatten()\n",
    "    col = col.T.flatten()\n",
    "\n",
    "    # Re-center them\n",
    "    row = row - hs // 2 + hc\n",
    "    col = col - ws // 2 + wc\n",
    "    \n",
    "    # Remove out-of-bounds indices\n",
    "    df = pd.DataFrame({'row': row, 'col': col, 'data': data.flatten()})\n",
    "    df = df[(df.row >= 0) & (df.col >= 0) & (df.row < hb) & (df.col < wb)]\n",
    "    \n",
    "    # Return sparse matrix\n",
    "    row, col, data = df.row.tolist(), df.col.tolist(), df.data.tolist()\n",
    "    return csr_matrix((data, (row, col)), shape=MAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fitted-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_lat_lng(filts):\n",
    "    lat_idx_max = filts.max(1).argmax()\n",
    "    lng_idx_max = filts.max(0).argmax()\n",
    "    lat_max = (lat_idx_max/CONFIG.SCALE) - 90\n",
    "    lng_max = (lng_idx_max/CONFIG.SCALE) - 180\n",
    "    return lat_max, lng_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "wanted-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(indices, weights, top=None):\n",
    "    neighbor_locs = y[indices][0] # (K, 2)\n",
    "    neighbor_weights = weights[0]\n",
    "\n",
    "    main = deepcopy(MAIN)\n",
    "    rows = []\n",
    "    for lat_lng, weight in zip(neighbor_locs, neighbor_weights):\n",
    "        main += make_filter(lat_lng=lat_lng, weight=weight)\n",
    "    return get_best_lat_lng(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cleared-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neighbors(logits):\n",
    "    X_test = logits.reshape(1, -1)\n",
    "    distances, indices = NN.kneighbors(X_test)\n",
    "    weights = (1/distances)**CONFIG.M\n",
    "    weights /= weights.sum(1, keepdims=True)\n",
    "    pred = predict(indices, weights)\n",
    "    pred_df = pd.DataFrame([list(pred)]).rename(columns={0:'lat',1:'lng'})\n",
    "    \n",
    "    z1 = y[indices][0]\n",
    "    z2 = weights[0].reshape(-1,1)\n",
    "    data = pd.DataFrame(np.concatenate([z1, z2], 1))\n",
    "    data = data.rename(columns={0: 'lat', 1: 'lng', 2: 'similarity'})\n",
    "    data['size'] = 1\n",
    "\n",
    "    fig = px.scatter_mapbox(\n",
    "        data,\n",
    "        lat='lat',\n",
    "        lon='lng',\n",
    "        color='similarity',\n",
    "        size='size',\n",
    "        size_max=10,\n",
    "        color_continuous_scale=px.colors.sequential.Plasma_r,\n",
    "    )\n",
    "    \n",
    "    # Add green circle for prediction\n",
    "    pred_df['color'] = 'rgb(50,220,50)'\n",
    "    pred_df['size'] = 1\n",
    "    trace = px.scatter_mapbox(\n",
    "        pred_df, \n",
    "        lat='lat', \n",
    "        lon='lng',\n",
    "        size='size',\n",
    "        size_max=10,\n",
    "        color='color',\n",
    "        color_discrete_map='identity',\n",
    "    ).data[0]\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=(\n",
    "            \".       Most Similar Locations\"\n",
    "            \"<br>.       (the green dot is my guess for the true location)\"\n",
    "        ),\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        mapbox=dict(\n",
    "            center={'lat': pred_df.lat[0], 'lon': pred_df.lng[0]},\n",
    "            zoom=2,\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "elementary-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_neighbors(X[0]+np.random.randn(412)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "binding-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN LOGIC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "under-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_COUNTRY = ['United Arab Emirates','Albania', 'Argentina','American Samoa','Austria', 'Australia','Bangladesh','Belgium', 'Bulgaria','Bolivia, Plurinational State of','Brazil', 'Bhutan','Botswana', 'Canada','Switzerland','Chile', 'China','Colombia','Czech Republic','Germany','Denmark','Dominican Republic','Ecuador','Estonia','Egypt','Spain','Finland','Faroe Islands','France','United Kingdom','Ghana','Greenland','Greece', 'Guatemala', 'Hong Kong','Croatia','Hungary','Indonesia', 'Ireland','Israel','India','Iceland','Italy','Jordan','Japan','Kenya','Kyrgyzstan','Cambodia','Korea, Republic of','Sri Lanka', 'Lesotho','Lithuania','Latvia','Madagascar','Macedonia, the Former Yugoslav Republic of','Mongolia','Mexico','Malaysia','Nigeria','Netherlands','Norway','New Zealand','Peru','Philippines','Pakistan','Poland','Puerto Rico','Portugal','Romania','Serbia','Russian Federation','Sweden','Singapore','Slovenia','Slovakia','Senegal','Swaziland','Thailand','Tunisia','Turkey','Taiwan, Province of China','Ukraine','Uganda','United States','Uruguay','Viet Nam', 'South Africa']\n",
    "VOCAB_US = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "breathing-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_url(url):\n",
    "    n = r'([\\d\\.-]*)'\n",
    "    res = re.search(fr'@{n},{n},.*,{n}h,{n}t', url)\n",
    "    \n",
    "    # Not a google maps URL\n",
    "    if res is None:\n",
    "        return url\n",
    "    \n",
    "    lat, lng, heading, pitch = [float(res.group(i)) for i in range(1,5)]\n",
    "    # URL pitch ranges 0 to 180, scrape API ranges -90 to 90\n",
    "    pitch -= 90\n",
    "\n",
    "    scrub3key = 'AIzaSyABWCcImw44lzIqLHzBIJLngYLTx5El11M'\n",
    "    params = {\n",
    "        'size': '480x480',\n",
    "        'location': f'{lat},{lng}',\n",
    "        'heading': str(heading),\n",
    "        'pitch': str(pitch),\n",
    "        'fov': '105',\n",
    "        'key': scrub3key,\n",
    "    }\n",
    "    url = \"https://maps.googleapis.com/maps/api/streetview\"\n",
    "    url_params = \"&\".join(f\"{k}={v}\" for k, v in params.items())\n",
    "    return f\"{url}?{url_params}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "substantial-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(arr):\n",
    "    exp = np.exp(arr)\n",
    "    return exp / exp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "elect-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logits(NamedTuple):\n",
    "    COUNTRY: np.array\n",
    "    GEOCELL: np.array\n",
    "    US: np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "respected-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_out(url):\n",
    "    # Returns logits_country: List[float]\n",
    "    params = {\n",
    "        'code': 'iZP6dHFLCjWvmLQx9v1haxW8Du21Phk/hMTQj4c/aGJseXAMgWuOPw==',\n",
    "        'img': url,\n",
    "    }\n",
    "    model_url = 'https://countryfinal.azurewebsites.net/api/classify'\n",
    "    res = requests.get(url=model_url, params=params).json()\n",
    "    \n",
    "    return Logits(\n",
    "        COUNTRY = np.array(res['logits_country']),\n",
    "        GEOCELL = np.array(res['logits_geocell']),\n",
    "        US = np.array(res['logits_us']),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "productive-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_preds(model_out):\n",
    "    logits = model_out.COUNTRY\n",
    "    probs = softmax(logits)\n",
    "\n",
    "    df = pd.DataFrame({'Country': VOCAB_COUNTRY, 'Confidence': probs})\n",
    "    df = df.sort_values('Confidence', ascending=False)\n",
    "    df.Confidence = (df.Confidence * 100).round(2)\n",
    "    df = df[df.Confidence > 0.].iloc[:10]\n",
    "    df.Confidence = df.Confidence.astype(str) + '%'\n",
    "    df = df.set_index('Country')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "tamil-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_preds(model_out):\n",
    "    logits = model_out.US\n",
    "    probs = softmax(logits)\n",
    "\n",
    "    df = pd.DataFrame({'US State': VOCAB_US, 'Confidence': probs})\n",
    "    df = df.sort_values('Confidence', ascending=False)\n",
    "    df.Confidence = (df.Confidence * 100).round(2)\n",
    "    df = df[df.Confidence > 0.].iloc[:10]\n",
    "    df.Confidence = df.Confidence.astype(str) + '%'\n",
    "    df = df.set_index('US State')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "minor-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_url = widgets.Text(placeholder='Paste the url here...')\n",
    "btn_run = widgets.Button(description=\"Predict Location\")\n",
    "err = widgets.Output()\n",
    "img_out = widgets.Output()\n",
    "waiting = widgets.Output()\n",
    "pred_out_country = widgets.Output()\n",
    "pred_out_us = widgets.Output()\n",
    "pred_loc = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "rubber-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    if len(text_url.value) == 0:\n",
    "        with err:\n",
    "            print(\"Please paste an image URL first!\")\n",
    "        return\n",
    "    \n",
    "    for elt in [img_out, pred_out_country, pred_out_us, pred_loc]:\n",
    "        elt.clear_output()\n",
    "    \n",
    "    url = convert_url(text_url.value)\n",
    "    with urlopen(url) as testImage:\n",
    "        image = Image.open(testImage)\n",
    "        image.thumbnail((256,256), Image.ANTIALIAS)\n",
    "    \n",
    "    with img_out:\n",
    "        display(image)\n",
    "    \n",
    "    with waiting:\n",
    "        print(\"Predicting... (takes about 15 seconds)\")\n",
    "    model_out = get_model_out(url)\n",
    "    waiting.clear_output()\n",
    "    \n",
    "    with pred_out_country:\n",
    "        display(country_preds(model_out))\n",
    "    \n",
    "    with pred_out_us:\n",
    "        display(us_preds(model_out))\n",
    "    \n",
    "    logits_cat = np.concatenate([model_out.COUNTRY, model_out.GEOCELL, model_out.US])\n",
    "    with pred_loc:\n",
    "        plot_neighbors(logits_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "alert-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "sublime-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = widgets.VBox([\n",
    "    widgets.Label(\"Enter any image URL (can be copy-pasted from Google Street View)\"),\n",
    "    text_url,\n",
    "    btn_run,\n",
    "    err,\n",
    "    img_out,\n",
    "    waiting,\n",
    "    widgets.HBox([pred_out_country, pred_out_us]),\n",
    "])\n",
    "\n",
    "main = widgets.VBox(\n",
    "    [content, pred_loc],\n",
    "    layout=widgets.Layout(\n",
    "        display='flex',\n",
    "        flex_flow='column',\n",
    "        align_items='center',\n",
    "        width='80%',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fossil-capacity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e64221a174941fab277862f1e8f6a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='Enter any image URL (can be copy-pasted from Google Street View)'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Wellesley, MA\n",
    "https://www.google.com/maps/@42.3001618,-71.2873389,3a,75y,282.13h,90.85t/data=!3m7!1e1!3m5!1sAfuLRKxkRWTKquuYzD9P4A!2e0!6shttps:%2F%2Fstreetviewpixels-pa.googleapis.com%2Fv1%2Fthumbnail%3Fpanoid%3DAfuLRKxkRWTKquuYzD9P4A%26cb_client%3Dmaps_sv.tactile.gps%26w%3D203%26h%3D100%26yaw%3D17.52565%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656\n",
    "\n",
    "Ireland\n",
    "https://www.google.com/maps/@52.4622135,-8.5005979,3a,75y,283.8h,93.24t/data=!3m7!1e1!3m5!1snwfVyxU9kwNpqZTjleScFg!2e0!6shttps:%2F%2Fstreetviewpixels-pa.googleapis.com%2Fv1%2Fthumbnail%3Fpanoid%3DnwfVyxU9kwNpqZTjleScFg%26cb_client%3Dmaps_sv.tactile.gps%26w%3D203%26h%3D100%26yaw%3D193.45317%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
